{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cpo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPx2dsPl0q399wbj6MEUn+B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertRasinski/Face_Detection_Machine_Learning/blob/main/cpo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GjL3WkRtzSy"
      },
      "source": [
        "Downloading tools to measure time and memory usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiEf1Sy90gbF"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ng4WsjAt3WF"
      },
      "source": [
        "Importing the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l53TnFCb-gl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "from IPython.display import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps1ene5Fuonj"
      },
      "source": [
        "Connecting to the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5kbeGMxcFVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65c80d6-91c4-4926-d81b-2aee07579599"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub-IC2RQuvBT"
      },
      "source": [
        "Loading image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH9GK1X1cH0R"
      },
      "source": [
        "trainingDatasetPath = \"/content/drive/MyDrive/data/training\"\n",
        "validationDatasetPath = \"/content/drive/MyDrive/data/validation\"\n",
        "testingDatasetPath = \"/content/drive/MyDrive/data/testing\"\n",
        "\n",
        "trainingDatasetImageGenerator = ImageDataGenerator(rescale=1./255,\n",
        "  rotation_range=20,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.3,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='nearest')\n",
        "\n",
        "validationDatasetImageGenerator = ImageDataGenerator(rescale=1./255,\n",
        "  rotation_range=20,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.3,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='nearest')\n",
        "\n",
        "testingDatasetImageGenerator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "trainingDataset = trainingDatasetImageGenerator.flow_from_directory(trainingDatasetPath, target_size=(128,128), batch_size=64, class_mode='binary')\n",
        "validationDataset = validationDatasetImageGenerator.flow_from_directory(validationDatasetPath, target_size=(128,128), batch_size=64, class_mode='binary')\n",
        "testingDataset = testingDatasetImageGenerator.flow_from_directory(testingDatasetPath, target_size=(128,128), batch_size=64, class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAhWJiTFvCAc"
      },
      "source": [
        "Show sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffOGtBB2w8PY"
      },
      "source": [
        "plt.imshow(trainingDataset[0][0][0])\n",
        "plt.imshow(validationDataset[0][0][0])\n",
        "plt.imshow(testingDataset[0][0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhaUymxTvbZs"
      },
      "source": [
        "Preparing the structure of the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytYcVf5fG0B9"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu, input_shape=(128, 128, 3)),\n",
        "  tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
        "  metrics=['binary_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgVifqMVvnSt"
      },
      "source": [
        "Show the structure of the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5w8ecAYXgcH"
      },
      "source": [
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtU7Ir-bvzme"
      },
      "source": [
        "Learn model, save model and plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h5mh66Cewaf"
      },
      "source": [
        "wandb.init()\n",
        "history = model.fit(\n",
        "  trainingDataset,\n",
        "  epochs=10,\n",
        "  validation_data=validationDataset,\n",
        "  verbose=1\n",
        "  )\n",
        "\n",
        "export_model_dir = '/content/drive/MyDrive/model'\n",
        "model.save(export_model_dir)\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDp_4kFhwBa2"
      },
      "source": [
        "Load saved model from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kclabea8fu9Y"
      },
      "source": [
        "export_model_dir = '/content/drive/MyDrive/model'\n",
        "model = tf.keras.models.load_model(export_model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odFywxbSwQ5s"
      },
      "source": [
        "Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgvKwl_9Py4L"
      },
      "source": [
        "wandb.init()\n",
        "resultsEvaluate = model.evaluate(testingDataset, verbose=1)\n",
        "\n",
        "print('accuracy:')\n",
        "print(resultsEvaluate[1])\n",
        "print('loss:')\n",
        "print(resultsEvaluate[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt14XGBHwTeE"
      },
      "source": [
        "Show confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDCp2brlQbIA"
      },
      "source": [
        "prediction = np.argmax(model.predict_generator(testingDataset, verbose=1), axis=1)\n",
        "\n",
        "confusionMatrix = confusion_matrix(testingDataset.classes, prediction)\n",
        "\n",
        "classes = []\n",
        "for key in testingDataset.class_indices:\n",
        "  classes.append(key)\n",
        "\n",
        "plt.imshow(confusionMatrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion matrix\")\n",
        "numberOfClasses = np.arange(len(classes))\n",
        "plt.xticks(numberOfClasses, classes, rotation=45)\n",
        "plt.yticks(numberOfClasses, classes)\n",
        "\n",
        "confusionMatrix = confusionMatrix.astype('float') / confusionMatrix.sum(axis=1)[:, np.newaxis]\n",
        "confusionMatrix = np.around(confusionMatrix, decimals=10)\n",
        "confusionMatrix[np.isnan(confusionMatrix)] = 0.0\n",
        "thresh = confusionMatrix.max() / 2.\n",
        "\n",
        "for i, j in itertools.product(range(confusionMatrix.shape[0]), range(confusionMatrix.shape[1])):\n",
        "  plt.text(j, i, confusionMatrix[i, j],\n",
        "           horizontalalignment=\"center\",\n",
        "           color=\"white\" if confusionMatrix[i, j] > thresh else \"black\")\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVzWix5cwd4D"
      },
      "source": [
        "Use model to predict a given image from a desktop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPTvuioPMIbx"
      },
      "source": [
        "predictFile = files.upload()\n",
        "\n",
        "fileName = list(predictFile.keys())[0]\n",
        "\n",
        "img = image.load_img(fileName, target_size=(128, 128))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "img = img / 255\n",
        "imgOpenCV = cv2.imread(fileName)\n",
        "imgOpenCV = cv2.resize(imgOpenCV, (256,256))\n",
        "\n",
        "result = model.predict(img, batch_size=1)\n",
        "print(result)\n",
        "if (result[0][0] < 0.5):\n",
        "  imgOpenCV = cv2.rectangle(imgOpenCV, (0,0),(62, 32), (0, 0, 0), -1)\n",
        "  imgOpenCV = cv2.putText(imgOpenCV, \"face\", (2,22), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2)\n",
        "else:\n",
        "  imgOpenCV = cv2.rectangle(imgOpenCV, (0,0),(102, 32), (0, 0, 0), -1)\n",
        "  imgOpenCV = cv2.putText(imgOpenCV, \"no face\", (2,22), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2)\n",
        "\n",
        "cv2_imshow(imgOpenCV)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}